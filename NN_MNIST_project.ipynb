{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f563e52",
   "metadata": {},
   "source": [
    "<b><h3>Defining the Neural Network</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8cf9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import random\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "# neural network class definition\n",
    "# 3 layer neural network\n",
    "class neuralNetwork:\n",
    "    \n",
    "    #initialize the neural network\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # set the number of nodes in each input, hidden and output layer\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        #setting the weights\n",
    "        #get the same weights each time for testing purposes\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # weights between input layer and the hidden layer\n",
    "        self.wih = np.random.normal(0.0, pow(self.input_nodes, -0.5),(self.hidden_nodes, self.input_nodes))\n",
    "        \n",
    "        # weights between the hidden layer and the output layer\n",
    "        self.who = np.random.normal(0.0, pow(self.hidden_nodes, -0.5),(self.output_nodes, self.hidden_nodes))\n",
    "        \n",
    "        #set the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # our activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "    #train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "\n",
    "        #calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "              \n",
    "        # calculate signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "              \n",
    "        # error is the (target - actual program output)\n",
    "        node_errors = (targets - final_outputs) \n",
    "         \n",
    "        # hidden layer error is the outputs_errors, split by the weights, recombined at the hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, node_errors)\n",
    "   \n",
    "        #update the weights for the links between the hidden and output layers\n",
    "        self.who += self.learning_rate * np.dot((node_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        self.wih += self.learning_rate * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "        \n",
    "    #query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert input list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        \n",
    "        #calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        \n",
    "        # calculate signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    def get_wih(self):\n",
    "        return self.wih\n",
    "    \n",
    "    def get_who(self):\n",
    "        return self.who\n",
    "    \n",
    "    # Save the weights to a file\n",
    "    def save_weights(self, wih_filename, who_filename):\n",
    "        np.save(wih_filename, self.wih)\n",
    "        np.save(who_filename, self.who)\n",
    "\n",
    "    # Load weights from a file\n",
    "    def load_weights(self, wih_filename, who_filename):\n",
    "        self.wih = np.load(wih_filename)\n",
    "        self.who = np.load(who_filename)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"number of input nodes: {self.input_nodes}, number of hidden nodes: {self.hidden_nodes}, number of output nodes: {self.output_nodes}. learning rate: {self.learning_rate}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2848f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# create an instance of neural network\n",
    "n = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f156b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first number in the list is the label (the actual label of the image)\n",
    "# the subsequent 784 numbers (28x28 pixel image) are the 0-255 color values\n",
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_train.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines() #list of strings\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e28a10",
   "metadata": {},
   "source": [
    "<b><h3>Training the Neural Network</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98deff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data set of 60,000 records, and the test data set of 10,000 records. \n",
    "# train the neural network\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for record in training_data_list:\n",
    "        # split the record by the ',' commas\n",
    "        all_values = record.split(',')\n",
    "        # scale and shift the inputs\n",
    "        inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # create the target output values (all 0.01, except the desired label which is 0.99)\n",
    "        targets = np.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27b5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist data CSV file into a list\n",
    "test_data_file = open(\"mnist_test.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef642d15",
   "metadata": {},
   "source": [
    "<b><h3>Testing the Neural Network</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a93f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set \n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commans\n",
    "    all_values = record.split(',')\n",
    "    # the correct answer is the first vaklue\n",
    "    correct_label = int(all_values[0])\n",
    "    #print(f\"correct label: {correct_label}\")\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:])/ 255.0 * .99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # index with the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    #print(f\"network's answer {label}\")\n",
    "    if (label == correct_label):\n",
    "        scorecard.append(1)\n",
    "    else: \n",
    "        scorecard.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f1fabf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance = 0.9539\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print(\"performance =\", scorecard_array.sum() / len(scorecard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab422fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01599991 -0.00667789  0.02139185 ... -0.04943075  0.01183861\n",
      "   0.02006675]\n",
      " [ 0.02291382  0.04152061  0.03270424 ... -0.00712611  0.00531383\n",
      "   0.0213477 ]\n",
      " [-0.05911842 -0.02220795  0.02505338 ... -0.01731367  0.03454166\n",
      "   0.01872271]\n",
      " ...\n",
      " [-0.01805132 -0.02710683  0.0439468  ... -0.01413821 -0.02903203\n",
      "   0.02516235]\n",
      " [ 0.05626083 -0.07133662 -0.01522897 ...  0.00837109  0.02280319\n",
      "  -0.02540377]\n",
      " [-0.01576751 -0.02210506  0.03925871 ...  0.05392255  0.00636043\n",
      "   0.04698166]]\n"
     ]
    }
   ],
   "source": [
    "print(n.get_wih())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a258360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.10272608 -0.08230223 -0.90887733 ... -0.27667068  0.26148445\n",
      "   0.0347101 ]\n",
      " [-0.09871707 -0.17534633  0.17500402 ... -0.13929758 -0.4015827\n",
      "  -0.34943873]\n",
      " [-0.07599251  0.27584452 -0.49260233 ...  0.75086654  0.32984204\n",
      "   0.34563114]\n",
      " ...\n",
      " [-0.13351136 -0.12016041  0.01188731 ... -0.54272977  0.13928291\n",
      "  -0.15997738]\n",
      " [-0.00442076 -0.16443207  0.28179534 ...  0.49275226 -0.4976124\n",
      "   0.48967571]\n",
      " [-0.12046968  0.09706024 -0.32012933 ...  0.0696934  -0.62066515\n",
      "  -0.15048715]]\n"
     ]
    }
   ],
   "source": [
    "print(n.get_who())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bd16c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.save_weights('wih.npy', 'who.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c9e20",
   "metadata": {},
   "source": [
    "<b><h3>Defining a new Neural Network and loading saved weights</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb891e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# create an instance of neural network\n",
    "new_nn = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "new_nn.load_weights('wih.npy', 'who.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f4008",
   "metadata": {},
   "source": [
    "<b><h3>Testing the new Neural Network with the saved weights</h3></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e552362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.9539\n"
     ]
    }
   ],
   "source": [
    "# test the neural network with the new_nn instance\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network using new_nn\n",
    "    outputs = new_nn.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = np.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "    \n",
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = np.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ad8d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights Input-Hidden (wih):\n",
      " [[ 0.01599991 -0.00667789  0.02139185 ... -0.04943075  0.01183861\n",
      "   0.02006675]\n",
      " [ 0.02291382  0.04152061  0.03270424 ... -0.00712611  0.00531383\n",
      "   0.0213477 ]\n",
      " [-0.05911842 -0.02220795  0.02505338 ... -0.01731367  0.03454166\n",
      "   0.01872271]\n",
      " ...\n",
      " [-0.01805132 -0.02710683  0.0439468  ... -0.01413821 -0.02903203\n",
      "   0.02516235]\n",
      " [ 0.05626083 -0.07133662 -0.01522897 ...  0.00837109  0.02280319\n",
      "  -0.02540377]\n",
      " [-0.01576751 -0.02210506  0.03925871 ...  0.05392255  0.00636043\n",
      "   0.04698166]]\n",
      "\n",
      "Weights Hidden-Output (who):\n",
      " [[-0.10272608 -0.08230223 -0.90887733 ... -0.27667068  0.26148445\n",
      "   0.0347101 ]\n",
      " [-0.09871707 -0.17534633  0.17500402 ... -0.13929758 -0.4015827\n",
      "  -0.34943873]\n",
      " [-0.07599251  0.27584452 -0.49260233 ...  0.75086654  0.32984204\n",
      "   0.34563114]\n",
      " ...\n",
      " [-0.13351136 -0.12016041  0.01188731 ... -0.54272977  0.13928291\n",
      "  -0.15997738]\n",
      " [-0.00442076 -0.16443207  0.28179534 ...  0.49275226 -0.4976124\n",
      "   0.48967571]\n",
      " [-0.12046968  0.09706024 -0.32012933 ...  0.0696934  -0.62066515\n",
      "  -0.15048715]]\n"
     ]
    }
   ],
   "source": [
    "wih_loaded = np.load('wih.npy')\n",
    "who_loaded = np.load('who.npy')\n",
    "\n",
    "#print the weight matrices\n",
    "print(\"Weights Input-Hidden (wih):\\n\", wih_loaded)\n",
    "print(\"\\nWeights Hidden-Output (who):\\n\", who_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a60d23d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93d0483e80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the image\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "matplotlib.pyplot.imshow(image_array, cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70f60945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example calculations using the diagram below\n",
    "\n",
    "# 3-layer neural net\n",
    "# 3 input nodes, 3 hidden nodes, 3 output nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0645d8e",
   "metadata": {},
   "source": [
    "\n",
    "<div>\n",
    "    <img src=\"https://i.imgur.com/Fvj7t8A.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04264e9",
   "metadata": {},
   "source": [
    "we encode the weights into matrices.\n",
    "the weights between the input/hidden layer in the above graph are encoded in the following way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75e9302b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n             [w_1,1, w_2,1, w_3,1]\\nweights_ih = [w_1,2, w_2,2, w_3,2]\\n             [w_1,3, w_2,3, w_3,3]      \\neg\\n\\nthe weights between the input/hidden layer in the above graph are:\\n\\n[w_1,1 = 0.9,  w_2,1 = 0.3, w_3,1 = 0.4]\\n[w_1,2 = 0.2,  w_2,2 = 0.8, w_3,2 = 0.2]\\n[w_1,3 = 0.1,  w_2,3 = 0.5, w_3,3 = 0.6]\\n\\nwhich is represented in the code below, along with the inputs/weights_ho\\n(note: not all of the weights are shown in the diagram)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "             [w_1,1, w_2,1, w_3,1]\n",
    "weights_ih = [w_1,2, w_2,2, w_3,2]\n",
    "             [w_1,3, w_2,3, w_3,3]      \n",
    "eg\n",
    "\n",
    "the weights between the input/hidden layer in the above graph are:\n",
    "\n",
    "[w_1,1 = 0.9,  w_2,1 = 0.3, w_3,1 = 0.4]\n",
    "[w_1,2 = 0.2,  w_2,2 = 0.8, w_3,2 = 0.2]\n",
    "[w_1,3 = 0.1,  w_2,3 = 0.5, w_3,3 = 0.6]\n",
    "\n",
    "which is represented in the code below, along with the inputs/weights_ho\n",
    "(note: not all of the weights are shown in the diagram)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b43f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[0.9], [0.1], [0.8]])\n",
    "weights_ih = np.array([[0.9, 0.3, 0.4], [0.2, 0.8, 0.2], [0.1, 0.5, 0.6]])\n",
    "weights_ho = np.array([[0.3, 0.7, 0.5], [0.6, 0.5, 0.2], [0.8, 0.1, 0.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0b62122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer input calculatiom\n",
    "hidden_inputs = np.dot(weights_ih,inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f1e88",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/6E4M5kK.png\" width=\"400\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2da3f804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.16],\n",
       "       [0.42],\n",
       "       [0.62]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbf99b",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/SaFSRNZ.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec8fca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating hidden_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7a84f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_function = lambda x: scipy.special.expit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47eabfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_outputs = activation_function(hidden_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e297a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76133271],\n",
       "       [0.60348325],\n",
       "       [0.65021855]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5e313",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/UvfNuFy.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc3e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the output layer inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9f38a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer_inputs = np.dot(weights_ho,hidden_outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49d490d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97594736],\n",
       "       [0.88858496],\n",
       "       [1.25461119]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10b1fa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72630335],\n",
       "       [0.70859807],\n",
       "       [0.77809706]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the output layers output\n",
    "output_layer_outputs = activation_function(output_layer_inputs)\n",
    "output_layer_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c1222",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/h9ifRY5.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12118ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the multivariate chain rule, we obtain the gradient descent algorithms\n",
    "# we dropped the constant 2 term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2adc6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f8f5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_who(who, node_errors, final_outputs, hidden_outputs):\n",
    "    who += learning_rate * np.dot((node_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "    return who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bee2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_wih(hidden_errors, hidden_outputs, inputs, wih):\n",
    "    wih += learning_rate * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "    return wih"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842c9d5",
   "metadata": {},
   "source": [
    " let's consider a simpler neural network to see how gradient descent is used to update the weight who_11.\n",
    " first we will need to see how to calculate the error terms, which are node_errors and hidden_errors.\n",
    " we will only need the node_errors term for our example, but we also show how to obtain hidden_errors for updating wih.\n",
    " the node_errors and hidden_errors terms are used to insert into the gradient descent algorithms for updating who and wih."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1400da3",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/2iCQMhS.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fad8e0",
   "metadata": {},
   "source": [
    " node_errors is calculated as (target - actual). this is calculating the term that appears in\n",
    " the gradient descent algorithm for updating the weights who. \n",
    " note: this is distinct from calculating the loss, we are merely getting the term that appears in the gradient descent algorithm for who. \n",
    "in this example the calculation has already been done for us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0be43f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_errors = np.array([[0.8], [0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaf088fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate the hidden_errors term that appears in the gradient descent algorithm\n",
    "# for wih we do what is seen below\n",
    "# first we have to obtain the who matrix which is:\n",
    "who = np.array([[2.0/(2.0+3.0), 3.0/(3.0+2.0)], [1.0/(1.0+4.0), 4.0/(4.0+1.0)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befe76f",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/0lObJPw.png\" width=\"400\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "445e875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we tranpose the who matrix and multiply it by the node errors\n",
    "hidden_errors = np.dot(who.T, node_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a713a85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42],\n",
       "       [0.88]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the term that appears in the gradient descent algorithm for calculating wih\n",
    "hidden_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624bc384",
   "metadata": {},
   "source": [
    "in this example we now have the node_error and hidden_error to insert into the gradient descent algorithms.\n",
    "the actual code drops the denominator/normalization terms that appear in the who matrix, whereas the handwritten example above includes it. from henceforth we will also drop the normalization. \n",
    "now that we have node_errors let's the updated weight who_11, which is currently equal to 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e61436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the relevant node error for who_1,1 is 0.8\n",
    "node_error = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f9f64",
   "metadata": {},
   "source": [
    " before we move further we will review some background material: the book's derivation of the gradient descent algorithm is included below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f61d2d8",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/bDAuYGs.png\" width=\"400\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca5f8b",
   "metadata": {},
   "source": [
    " putting it all together with the learning rate (where we drop the constant term 2), we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa26d2",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src=\"https://i.imgur.com/37P0suW.png\" width=\"400\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ed07bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the old weight are adjusted by the negative of the error's slope\n",
    "# we want to decrease the new weight if we have a positive slope\n",
    "# and increase it if we have a negative slope\n",
    "# also note dE/dwjk has a negative sign\n",
    "# there is a distinct negative sign in front of the learning rate\n",
    "# these two negatives signs cancel each other out and do not appear in\n",
    "# the gradient descent algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bae24d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_errors = np.array([[0.8], [0.5]])\n",
    "learning_rate = 0.1\n",
    "who = np.array([[2.0, 3.0], [1.0, 4.0]])\n",
    "hidden_outputs = np.array([[0.4], [0.5]])\n",
    "final_inputs = np.dot(who, hidden_outputs)\n",
    "final_outputs = activation_function(final_inputs).reshape(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e47c021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8],\n",
       "       [0.5]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd9366ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90887704],\n",
       "       [0.9168273 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76774ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08281957],\n",
       "       [0.076255  ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_outputs * (1-final_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54b8c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "who += learning_rate * np.dot((node_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "143ec336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.002650226143704"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our updated who_11 weight is below\n",
    "who[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06be4d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00265023, 3.00331278],\n",
       "       [1.0015251 , 4.00190637]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the rest of the who weight updates\n",
    "who"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
